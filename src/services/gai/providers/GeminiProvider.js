/**
 * Google Gemini Provider
 *
 * å¯¦ä½œ Google Gemini API çš„å‘¼å«é‚è¼¯
 */
import BaseProvider from './BaseProvider.js';

class GeminiProvider extends BaseProvider {
    constructor() {
        super({
            id: 'gemini',
            name: 'Google Gemini',
            apiKeyStorageKey: 'geminiApiKey',
            defaultModel: 'gemini-3-flash-preview',
            description: 'Google Gemini models with fast inference'
        });

        this.apiEndpoint = 'https://generativelanguage.googleapis.com/v1beta/models';
    }

    /**
     * å‘¼å« Gemini API
     * @param {string} systemPrompt - System prompt
     * @param {string} userPrompt - User prompt
     * @param {Object} jsonSchema - JSON Schema for structured output
     * @param {Object} options - é¡å¤–é¸é … (model, temperature, etc.)
     * @returns {Promise<Object>} æ¨™æº–åŒ–çš„å›æ‡‰æ ¼å¼
     */
    async callAPI(systemPrompt, userPrompt, jsonSchema, options = {}) {
        const apiKey = await this.getApiKey();

        if (!apiKey) {
            throw new Error(`${this.name} API Key not found. Please set it in Options.`);
        }

        const startTime = Date.now();
        const model = options.model || this.defaultModel;

        try {
            console.log(`ğŸš€ [NEW ARCHITECTURE] Using ${this.name} Provider (Modular)`);
            this.log('API Request', {
                model: model,
                systemPromptLength: systemPrompt.length,
                userPromptLength: userPrompt.length
            });

            const response = await fetch(
                `${this.apiEndpoint}/${model}:generateContent?key=${apiKey}`,
                {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        systemInstruction: {
                            parts: [
                                { text: systemPrompt }
                            ]
                        },
                        contents: [{
                            parts: [
                                { text: userPrompt }
                            ]
                        }],
                        generationConfig: {
                            responseMimeType: "application/json",
                            responseJsonSchema: jsonSchema.schema, // Gemini ä½¿ç”¨ schema å±¬æ€§
                            temperature: options.temperature || 1,
                            ...options.additionalParams
                        }
                    })
                }
            );

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            const duration = Date.now() - startTime;

            // è¨˜éŒ„æ•ˆèƒ½æ•¸æ“š
            console.groupCollapsed(`${this.name} API Call (${duration}ms)`);
            console.log("Model:", model);
            console.log("Token Usage:", data.usageMetadata);
            console.log("Full Response:", data);
            console.groupEnd();

            return this.formatResponse(data, duration);

        } catch (error) {
            const duration = Date.now() - startTime;
            this.logError(`API call failed after ${duration}ms`, error);
            throw error;
        }
    }

    /**
     * æ ¼å¼åŒ–å›æ‡‰ï¼ˆè½‰æ›ç‚º OpenAI ç›¸å®¹æ ¼å¼ï¼‰
     * @param {Object} rawResponse - Gemini API åŸå§‹å›æ‡‰
     * @param {number} duration - åŸ·è¡Œæ™‚é–“ï¼ˆæ¯«ç§’ï¼‰
     * @returns {Object} æ¨™æº–åŒ–æ ¼å¼
     */
    formatResponse(rawResponse, duration) {
        // æå– Gemini å›æ‡‰æ–‡å­—
        const contentText = rawResponse.candidates?.[0]?.content?.parts?.[0]?.text;

        if (!contentText) {
            throw new Error("Empty response from Gemini");
        }

        // è½‰æ› Token ç”¨é‡æ ¼å¼ï¼ˆGemini ä½¿ç”¨ usageMetadataï¼‰
        const usage = {
            prompt_tokens: rawResponse.usageMetadata?.promptTokenCount || 0,
            completion_tokens: rawResponse.usageMetadata?.candidatesTokenCount || 0,
            total_tokens: rawResponse.usageMetadata?.totalTokenCount || 0,
            totalTokenCount: rawResponse.usageMetadata?.totalTokenCount || 0 // ä¿ç•™åŸå§‹æ¬„ä½
        };

        // æ¨¡æ“¬ OpenAI å›æ‡‰çµæ§‹
        return {
            choices: [{
                message: {
                    content: contentText,
                    role: 'assistant'
                },
                finish_reason: rawResponse.candidates?.[0]?.finishReason || 'stop'
            }],
            usage: usage,
            duration: duration,
            model: this.defaultModel,
            provider: this.id
        };
    }
}

export default GeminiProvider;
