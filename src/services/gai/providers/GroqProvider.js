/**
 * Groq Provider
 *
 * å¯¦ä½œ Groq API çš„å‘¼å«é‚è¼¯
 * Groq æä¾›è¶…å¿«é€Ÿçš„ LLM æ¨ç†æœå‹™ï¼ŒAPI æ ¼å¼èˆ‡ OpenAI ç›¸å®¹
 */
import BaseProvider from './BaseProvider.js';

class GroqProvider extends BaseProvider {
    constructor() {
        super({
            id: 'groq',
            name: 'Groq',
            apiKeyStorageKey: 'groqApiKey',
            defaultModel: 'llama-3.3-70b-versatile',
            description: 'å‘¼å«æ¨¡å‹ï¼šllama-3.3-70b-versatile | å–å¾— API Keyï¼šhttps://console.groq.com/'
        });

        this.apiEndpoint = 'https://api.groq.com/openai/v1/chat/completions';
    }

    /**
     * å‘¼å« Groq API
     * @param {string} systemPrompt - System prompt
     * @param {string} userPrompt - User prompt
     * @param {Object} jsonSchema - JSON Schema for structured output
     * @param {Object} options - é¡å¤–é¸é … (model, temperature, etc.)
     * @returns {Promise<Object>} æ¨™æº–åŒ–çš„å›æ‡‰æ ¼å¼
     */
    async callAPI(systemPrompt, userPrompt, jsonSchema, options = {}) {
        // ä½¿ç”¨æ–°çš„ getNextApiKey() æ”¯æ´é›™ Key è¼ªæµ
        const { key: apiKey, keyIndex, message } = await this.getNextApiKey();

        if (!apiKey) {
            throw new Error(`${this.name} API Key not found. Please set it in Options.`);
        }

        const startTime = Date.now();

        try {
            console.log(`ğŸš€ [NEW ARCHITECTURE] Using ${this.name} Provider (Modular)`);
            console.log(`ğŸ”‘ [${this.name}] ${message}`);  // é¡¯ç¤ºä½¿ç”¨å“ªå€‹ Key

            // Groq æ”¯æ´ OpenAI ç›¸å®¹çš„ response_formatï¼Œä½†ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬
            // å¦‚æœæä¾›äº† jsonSchemaï¼Œå°‡ schema è³‡è¨ŠåŠ å…¥ system prompt ä¸¦å•Ÿç”¨ JSON æ¨¡å¼
            let enhancedSystemPrompt = systemPrompt;
            const requestBody = {
                model: options.model || this.defaultModel,
                messages: [
                    {
                        role: "system",
                        content: enhancedSystemPrompt
                    },
                    {
                        role: "user",
                        content: userPrompt
                    }
                ],
                temperature: options.temperature || 1,
                max_completion_tokens: options.maxTokens || 16384,
                top_p: options.topP || 1
            };

            // å¦‚æœæœ‰ jsonSchemaï¼Œå•Ÿç”¨ JSON æ¨¡å¼
            if (jsonSchema && jsonSchema.schema) {
                requestBody.response_format = {
                    type: "json_object"
                };

                // å°‡ schema è³‡è¨ŠåŠ å…¥ system prompt ä»¥æé«˜ JSON çµæ§‹æº–ç¢ºæ€§
                enhancedSystemPrompt = `${systemPrompt}\n\nä½ å¿…é ˆå›å‚³ç¬¦åˆä»¥ä¸‹ JSON schema çš„æ ¼å¼ï¼š\n${JSON.stringify(jsonSchema.schema, null, 2)}`;
                requestBody.messages[0].content = enhancedSystemPrompt;
            }

            // åŠ å…¥å…¶ä»–é¡å¤–åƒæ•¸
            if (options.additionalParams) {
                Object.assign(requestBody, options.additionalParams);
            }

            // ä¼°ç®—ä¸¦è¨˜éŒ„ Token ç”¨é‡ï¼ˆåœ¨å‘¼å« API å‰ï¼Œä½¿ç”¨æœ€çµ‚çš„ enhancedSystemPromptï¼‰
            this.logTokenEstimation(enhancedSystemPrompt, userPrompt, {
                model: options.model || this.defaultModel
            });

            this.log('API Request', {
                model: options.model || this.defaultModel,
                systemPromptLength: enhancedSystemPrompt.length,
                userPromptLength: userPrompt.length
            });

            const response = await fetch(this.apiEndpoint, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${apiKey}`
                },
                body: JSON.stringify(requestBody)
            });

            if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                throw new Error(errorData.error?.message || `HTTP error! status: ${response.status}`);
            }

            const data = await response.json();
            const duration = Date.now() - startTime;

            // è¨˜éŒ„æ•ˆèƒ½æ•¸æ“š
            console.groupCollapsed(`${this.name} API Call (${duration}ms)`);
            console.log("Model:", options.model || this.defaultModel);
            console.log("Token Usage:", data.usage);
            console.log("Full Response:", data);
            console.groupEnd();

            return this.formatResponse(data, duration, keyIndex);

        } catch (error) {
            const duration = Date.now() - startTime;
            this.logError(`API call failed after ${duration}ms`, error);
            throw error;
        }
    }

    /**
     * æ ¼å¼åŒ–å›æ‡‰ï¼ˆGroq ä½¿ç”¨ OpenAI ç›¸å®¹æ ¼å¼ï¼‰
     * @param {Object} rawResponse - Groq API åŸå§‹å›æ‡‰
     * @param {number} duration - åŸ·è¡Œæ™‚é–“ï¼ˆæ¯«ç§’ï¼‰
     * @param {number} keyIndex - ä½¿ç”¨çš„ API Key ç´¢å¼•ï¼ˆ0 æˆ– 1ï¼‰
     * @returns {Object} æ¨™æº–åŒ–æ ¼å¼
     */
    formatResponse(rawResponse, duration, keyIndex = 0) {
        // è™•ç†æ¨ç†æ¨¡å‹å¯èƒ½å°‡å…§å®¹æ”¾åœ¨ reasoning æˆ– reasoning_content çš„æƒ…æ³
        const choices = rawResponse.choices?.map(choice => {
            if (choice.message && !choice.message.content) {
                const extractedContent = choice.message.reasoning || choice.message.reasoning_content;
                if (extractedContent) {
                    return {
                        ...choice,
                        message: {
                            ...choice.message,
                            content: extractedContent,
                            isReasoning: true
                        }
                    };
                }
            }
            return choice;
        });

        return {
            choices: choices || rawResponse.choices,
            usage: rawResponse.usage,
            duration: duration,
            model: rawResponse.model,
            provider: this.id,
            keyUsed: `Key ${keyIndex + 1}`
        };
    }
}

export default GroqProvider;
